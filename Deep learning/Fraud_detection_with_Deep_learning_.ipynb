{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly"
      ],
      "metadata": {
        "id": "l5yW6jxVzHRd"
      },
      "id": "l5yW6jxVzHRd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "85d64261-b2bb-4690-80c6-f64548e97579",
      "metadata": {
        "id": "85d64261-b2bb-4690-80c6-f64548e97579"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model, layers, Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeF5AyVrAcWf",
        "outputId": "3b79ddb9-a966-4f76-db49-3c0b0e9caa0d"
      },
      "id": "OeF5AyVrAcWf",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b74a34fe-deca-464d-81ca-b485c2c8c1b0",
      "metadata": {
        "id": "b74a34fe-deca-464d-81ca-b485c2c8c1b0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/fraud detection/creditcard.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ac81f9a5-6833-4587-8097-ed0993f90532",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "ac81f9a5-6833-4587-8097-ed0993f90532",
        "outputId": "842c111e-ea9c-4589-deb7-bc36142bf8c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cb5ba00-6d46-4e6d-bfa5-386339156f5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cb5ba00-6d46-4e6d-bfa5-386339156f5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1cb5ba00-6d46-4e6d-bfa5-386339156f5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1cb5ba00-6d46-4e6d-bfa5-386339156f5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "86ca0f7b-3326-49c9-a4c4-e1fed28ceec2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "86ca0f7b-3326-49c9-a4c4-e1fed28ceec2",
        "outputId": "bc2d188e-bb51-4c24-c47a-a12c010aa9ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ed3dc4a-ca70-4df3-aff8-281527366a9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ed3dc4a-ca70-4df3-aff8-281527366a9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ed3dc4a-ca70-4df3-aff8-281527366a9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ed3dc4a-ca70-4df3-aff8-281527366a9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6eab728a-3f93-4048-9960-4f0a726604a6",
      "metadata": {
        "id": "6eab728a-3f93-4048-9960-4f0a726604a6"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f97cfcb6-49fd-4004-b8d5-c9cfe0a2be9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f97cfcb6-49fd-4004-b8d5-c9cfe0a2be9c",
        "outputId": "f500fd89-7696-4a75-96ac-9aef19d6a2e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 283726 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    283726 non-null  float64\n",
            " 1   V1      283726 non-null  float64\n",
            " 2   V2      283726 non-null  float64\n",
            " 3   V3      283726 non-null  float64\n",
            " 4   V4      283726 non-null  float64\n",
            " 5   V5      283726 non-null  float64\n",
            " 6   V6      283726 non-null  float64\n",
            " 7   V7      283726 non-null  float64\n",
            " 8   V8      283726 non-null  float64\n",
            " 9   V9      283726 non-null  float64\n",
            " 10  V10     283726 non-null  float64\n",
            " 11  V11     283726 non-null  float64\n",
            " 12  V12     283726 non-null  float64\n",
            " 13  V13     283726 non-null  float64\n",
            " 14  V14     283726 non-null  float64\n",
            " 15  V15     283726 non-null  float64\n",
            " 16  V16     283726 non-null  float64\n",
            " 17  V17     283726 non-null  float64\n",
            " 18  V18     283726 non-null  float64\n",
            " 19  V19     283726 non-null  float64\n",
            " 20  V20     283726 non-null  float64\n",
            " 21  V21     283726 non-null  float64\n",
            " 22  V22     283726 non-null  float64\n",
            " 23  V23     283726 non-null  float64\n",
            " 24  V24     283726 non-null  float64\n",
            " 25  V25     283726 non-null  float64\n",
            " 26  V26     283726 non-null  float64\n",
            " 27  V27     283726 non-null  float64\n",
            " 28  V28     283726 non-null  float64\n",
            " 29  Amount  283726 non-null  float64\n",
            " 30  Class   283726 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 69.3 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a5767cfa-49b5-41f9-9ff5-36a2952b80c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a5767cfa-49b5-41f9-9ff5-36a2952b80c8",
        "outputId": "aae79d6c-a8fd-4c09-b245-8055c44097a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        missing_values  % of total\n",
              "Time                 0         0.0\n",
              "V1                   0         0.0\n",
              "V2                   0         0.0\n",
              "V3                   0         0.0\n",
              "V4                   0         0.0\n",
              "V5                   0         0.0\n",
              "V6                   0         0.0\n",
              "V7                   0         0.0\n",
              "V8                   0         0.0\n",
              "V9                   0         0.0\n",
              "V10                  0         0.0\n",
              "V11                  0         0.0\n",
              "V12                  0         0.0\n",
              "V13                  0         0.0\n",
              "V14                  0         0.0\n",
              "V15                  0         0.0\n",
              "V16                  0         0.0\n",
              "V17                  0         0.0\n",
              "V18                  0         0.0\n",
              "V19                  0         0.0\n",
              "V20                  0         0.0\n",
              "V21                  0         0.0\n",
              "V22                  0         0.0\n",
              "V23                  0         0.0\n",
              "V24                  0         0.0\n",
              "V25                  0         0.0\n",
              "V26                  0         0.0\n",
              "V27                  0         0.0\n",
              "V28                  0         0.0\n",
              "Amount               0         0.0\n",
              "Class                0         0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d2399be-be81-4bc6-9cf1-bc00535bc977\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>missing_values</th>\n",
              "      <th>% of total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V5</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V6</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V7</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V8</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V9</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V10</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V11</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V12</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V13</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V14</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V15</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V16</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V17</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V18</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V19</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V20</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V21</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V22</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V23</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V24</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V25</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V26</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V27</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V28</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Amount</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d2399be-be81-4bc6-9cf1-bc00535bc977')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d2399be-be81-4bc6-9cf1-bc00535bc977 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d2399be-be81-4bc6-9cf1-bc00535bc977');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "missing_values = df.isna().sum().to_frame()\n",
        "missing_values = missing_values.rename(columns= {0: 'missing_values'})\n",
        "missing_values['% of total'] = (missing_values['missing_values'] / df.shape[0]).round(2)\n",
        "missing_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "89187ce3-051b-42f4-93b1-b00390cfda1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89187ce3-051b-42f4-93b1-b00390cfda1b",
        "outputId": "96e9438a-ae6a-44ad-dece-4783638dda9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    283253\n",
              "1       473\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df['Class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5bf42cb2-486d-4508-8116-6f508548c054",
      "metadata": {
        "id": "5bf42cb2-486d-4508-8116-6f508548c054"
      },
      "outputs": [],
      "source": [
        "fraud = df[df['Class'] == 1]\n",
        "valid = df[df['Class'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3264bb29-f5c9-4f6f-a241-53fc1369ec14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3264bb29-f5c9-4f6f-a241-53fc1369ec14",
        "outputId": "e4875afd-34e9-412e-cd60-42bd1405374a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 473 fraudulent\n",
            "There are 283253 Valid Transaction\n",
            "There are 0.17  % of fraudulent transaction in the dataframe\n"
          ]
        }
      ],
      "source": [
        "print('There are', len(fraud), 'fraudulent')\n",
        "print('There are', len(valid), 'Valid Transaction')\n",
        "\n",
        "print('There are', f'{len(fraud)/len(df) * 100 :.2f} ',  '% of fraudulent transaction in the dataframe')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fdbc3115-9759-48ec-9c18-f8806a17f993",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "fdbc3115-9759-48ec-9c18-f8806a17f993",
        "outputId": "f6634ff2-a20c-4f19-a321-427c24ec1b47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"3af084b1-beca-40dc-87d5-d7f5b86ac195\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3af084b1-beca-40dc-87d5-d7f5b86ac195\")) {                    Plotly.newPlot(                        \"3af084b1-beca-40dc-87d5-d7f5b86ac195\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"label=%{label}<br>value=%{value}<extra></extra>\",\"labels\":[\"Genuine\",\"Fraudulent\"],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"values\":[283253,473],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Genuine vs Fraudulent Transactions\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3af084b1-beca-40dc-87d5-d7f5b86ac195');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# visualise class representation in the data set\n",
        "fraud_or_valid = df['Class'].value_counts().tolist()\n",
        "labels = ['Genuine', 'Fraudulent']\n",
        "fig = px.pie(values=fraud_or_valid, names=labels, \n",
        "            title='Genuine vs Fraudulent Transactions')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1dd330d-90fc-4402-b0ad-429647515a1e",
      "metadata": {
        "id": "b1dd330d-90fc-4402-b0ad-429647515a1e"
      },
      "source": [
        "There are very low numbers of fraudulent transaction in the data compared to the number of valid data. Making the dataset highly imbalanced resulting in the model not being able to learn much from the miniority class. we can overcome this problem by using class weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cf096acb-7544-41cf-8793-17cd41842b3b",
      "metadata": {
        "id": "cf096acb-7544-41cf-8793-17cd41842b3b"
      },
      "outputs": [],
      "source": [
        "#slice dataset to x and y\n",
        "\n",
        "x = df.drop(['Class', 'Time'], axis=1)\n",
        "y = df['Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "884c23be-3452-4cab-87c7-1096fb4ed845",
      "metadata": {
        "id": "884c23be-3452-4cab-87c7-1096fb4ed845"
      },
      "outputs": [],
      "source": [
        "#split dataset into training and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size = 0.3, random_state = 123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute class weight to correct imbalance during training\n",
        "\n",
        "weight = compute_class_weight('balanced', classes = np.unique(y_train), y=y_train)\n",
        "class_weight = {0: weight[0],\n",
        "                1: weight[1]\n",
        "                }\n",
        "print(class_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfbAcVCeLEo0",
        "outputId": "28c0c6e8-0bb9-43ee-feab-08a92ae89c69"
      },
      "id": "YfbAcVCeLEo0",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0.5008346908617742, 1: 300.012084592145}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3a2c1ae3-ca7a-4567-a2c1-a8509aedc8c5",
      "metadata": {
        "id": "3a2c1ae3-ca7a-4567-a2c1-a8509aedc8c5"
      },
      "outputs": [],
      "source": [
        "#scale data using standardscaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train_scaled = scaler.transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "14c4b3ab-05fd-4d54-b384-44b65d5e99df",
      "metadata": {
        "id": "14c4b3ab-05fd-4d54-b384-44b65d5e99df"
      },
      "outputs": [],
      "source": [
        "#create a simple sequential model with 2 dense layer\n",
        "\n",
        "model = Sequential(layers=[\n",
        "    layers.Input(shape=(29,), dtype='float32'),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(2, activation='sigmoid')\n",
        "]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS =500\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n"
      ],
      "metadata": {
        "id": "86yVgJX4SFj0"
      },
      "id": "86yVgJX4SFj0",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics='accuracy')"
      ],
      "metadata": {
        "id": "M8tSXoVtWadp"
      },
      "id": "M8tSXoVtWadp",
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "          x_train_scaled, y_train, epochs=EPOCHS, \n",
        "          batch_size=4096, \n",
        "          validation_split=0.2,\n",
        "          class_weight=class_weight\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO4bqHQeDinN",
        "outputId": "d3e0c2c9-9f6a-4f17-ec4e-de9c69ea08b8"
      },
      "id": "HO4bqHQeDinN",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "39/39 [==============================] - 1s 10ms/step - loss: 0.3660 - accuracy: 0.8953 - val_loss: 0.3458 - val_accuracy: 0.9857\n",
            "Epoch 2/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.2435 - accuracy: 0.9849 - val_loss: 0.2431 - val_accuracy: 0.9859\n",
            "Epoch 3/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1945 - accuracy: 0.9876 - val_loss: 0.1932 - val_accuracy: 0.9850\n",
            "Epoch 4/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1644 - accuracy: 0.9864 - val_loss: 0.1519 - val_accuracy: 0.9882\n",
            "Epoch 5/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1460 - accuracy: 0.9898 - val_loss: 0.1360 - val_accuracy: 0.9869\n",
            "Epoch 6/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9883 - val_loss: 0.1233 - val_accuracy: 0.9864\n",
            "Epoch 7/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1225 - accuracy: 0.9855 - val_loss: 0.1027 - val_accuracy: 0.9884\n",
            "Epoch 8/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1154 - accuracy: 0.9899 - val_loss: 0.1050 - val_accuracy: 0.9859\n",
            "Epoch 9/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.9871 - val_loss: 0.0917 - val_accuracy: 0.9875\n",
            "Epoch 10/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.1038 - accuracy: 0.9863 - val_loss: 0.0857 - val_accuracy: 0.9880\n",
            "Epoch 11/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0988 - accuracy: 0.9902 - val_loss: 0.0874 - val_accuracy: 0.9864\n",
            "Epoch 12/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0944 - accuracy: 0.9870 - val_loss: 0.0786 - val_accuracy: 0.9882\n",
            "Epoch 13/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0910 - accuracy: 0.9884 - val_loss: 0.0796 - val_accuracy: 0.9875\n",
            "Epoch 14/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0865 - accuracy: 0.9891 - val_loss: 0.0718 - val_accuracy: 0.9891\n",
            "Epoch 15/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0826 - accuracy: 0.9899 - val_loss: 0.0714 - val_accuracy: 0.9887\n",
            "Epoch 16/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9895 - val_loss: 0.0665 - val_accuracy: 0.9895\n",
            "Epoch 17/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9900 - val_loss: 0.0634 - val_accuracy: 0.9902\n",
            "Epoch 18/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9907 - val_loss: 0.0667 - val_accuracy: 0.9891\n",
            "Epoch 19/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9899 - val_loss: 0.0600 - val_accuracy: 0.9907\n",
            "Epoch 20/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.9907 - val_loss: 0.0575 - val_accuracy: 0.9911\n",
            "Epoch 21/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 0.9912 - val_loss: 0.0587 - val_accuracy: 0.9906\n",
            "Epoch 22/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9922 - val_loss: 0.0595 - val_accuracy: 0.9900\n",
            "Epoch 23/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9898 - val_loss: 0.0499 - val_accuracy: 0.9923\n",
            "Epoch 24/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.9928 - val_loss: 0.0571 - val_accuracy: 0.9899\n",
            "Epoch 25/500\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9913 - val_loss: 0.0525 - val_accuracy: 0.9915\n",
            "Epoch 26/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9924 - val_loss: 0.0509 - val_accuracy: 0.9915\n",
            "Epoch 27/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9913 - val_loss: 0.0440 - val_accuracy: 0.9928\n",
            "Epoch 28/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0483 - accuracy: 0.9925 - val_loss: 0.0460 - val_accuracy: 0.9921\n",
            "Epoch 29/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9924 - val_loss: 0.0454 - val_accuracy: 0.9920\n",
            "Epoch 30/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.9931 - val_loss: 0.0409 - val_accuracy: 0.9928\n",
            "Epoch 31/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9926 - val_loss: 0.0438 - val_accuracy: 0.9922\n",
            "Epoch 32/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0405 - accuracy: 0.9929 - val_loss: 0.0405 - val_accuracy: 0.9927\n",
            "Epoch 33/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9932 - val_loss: 0.0446 - val_accuracy: 0.9916\n",
            "Epoch 34/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9922 - val_loss: 0.0326 - val_accuracy: 0.9944\n",
            "Epoch 35/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 0.9941 - val_loss: 0.0400 - val_accuracy: 0.9924\n",
            "Epoch 36/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9932 - val_loss: 0.0334 - val_accuracy: 0.9939\n",
            "Epoch 37/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9934 - val_loss: 0.0314 - val_accuracy: 0.9942\n",
            "Epoch 38/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0316 - accuracy: 0.9936 - val_loss: 0.0341 - val_accuracy: 0.9936\n",
            "Epoch 39/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9943 - val_loss: 0.0381 - val_accuracy: 0.9920\n",
            "Epoch 40/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9937 - val_loss: 0.0310 - val_accuracy: 0.9939\n",
            "Epoch 41/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0284 - accuracy: 0.9936 - val_loss: 0.0307 - val_accuracy: 0.9938\n",
            "Epoch 42/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 0.9943 - val_loss: 0.0298 - val_accuracy: 0.9940\n",
            "Epoch 43/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 0.9941 - val_loss: 0.0273 - val_accuracy: 0.9945\n",
            "Epoch 44/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 0.9951 - val_loss: 0.0298 - val_accuracy: 0.9938\n",
            "Epoch 45/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0238 - val_accuracy: 0.9953\n",
            "Epoch 46/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9949 - val_loss: 0.0303 - val_accuracy: 0.9933\n",
            "Epoch 47/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0227 - accuracy: 0.9949 - val_loss: 0.0240 - val_accuracy: 0.9950\n",
            "Epoch 48/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 0.0256 - val_accuracy: 0.9944\n",
            "Epoch 49/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0211 - accuracy: 0.9948 - val_loss: 0.0248 - val_accuracy: 0.9945\n",
            "Epoch 50/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 0.0249 - val_accuracy: 0.9942\n",
            "Epoch 51/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.0246 - val_accuracy: 0.9942\n",
            "Epoch 52/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.0225 - val_accuracy: 0.9949\n",
            "Epoch 53/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.0245 - val_accuracy: 0.9941\n",
            "Epoch 54/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0179 - accuracy: 0.9956 - val_loss: 0.0204 - val_accuracy: 0.9957\n",
            "Epoch 55/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.0233 - val_accuracy: 0.9942\n",
            "Epoch 56/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0200 - val_accuracy: 0.9958\n",
            "Epoch 57/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.0206 - val_accuracy: 0.9953\n",
            "Epoch 58/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.0203 - val_accuracy: 0.9953\n",
            "Epoch 59/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0152 - accuracy: 0.9959 - val_loss: 0.0205 - val_accuracy: 0.9950\n",
            "Epoch 60/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0148 - accuracy: 0.9959 - val_loss: 0.0196 - val_accuracy: 0.9955\n",
            "Epoch 61/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0174 - val_accuracy: 0.9961\n",
            "Epoch 62/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9966 - val_loss: 0.0184 - val_accuracy: 0.9958\n",
            "Epoch 63/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0160 - val_accuracy: 0.9964\n",
            "Epoch 64/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.0178 - val_accuracy: 0.9957\n",
            "Epoch 65/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.0167 - val_accuracy: 0.9960\n",
            "Epoch 66/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.0156 - val_accuracy: 0.9965\n",
            "Epoch 67/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.0176 - val_accuracy: 0.9957\n",
            "Epoch 68/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0162 - val_accuracy: 0.9961\n",
            "Epoch 69/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.0176 - val_accuracy: 0.9956\n",
            "Epoch 70/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0145 - val_accuracy: 0.9967\n",
            "Epoch 71/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0139 - val_accuracy: 0.9969\n",
            "Epoch 72/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.0152 - val_accuracy: 0.9963\n",
            "Epoch 73/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0143 - val_accuracy: 0.9966\n",
            "Epoch 74/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0146 - val_accuracy: 0.9965\n",
            "Epoch 75/500\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.0136 - val_accuracy: 0.9968\n",
            "Epoch 76/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
            "Epoch 77/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0139 - val_accuracy: 0.9966\n",
            "Epoch 78/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0132 - val_accuracy: 0.9969\n",
            "Epoch 79/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0127 - val_accuracy: 0.9970\n",
            "Epoch 80/500\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0123 - val_accuracy: 0.9970\n",
            "Epoch 81/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.0123 - val_accuracy: 0.9970\n",
            "Epoch 82/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0140 - val_accuracy: 0.9967\n",
            "Epoch 83/500\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0122 - val_accuracy: 0.9971\n",
            "Epoch 84/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
            "Epoch 85/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0110 - val_accuracy: 0.9974\n",
            "Epoch 86/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0107 - val_accuracy: 0.9974\n",
            "Epoch 87/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0103 - val_accuracy: 0.9974\n",
            "Epoch 88/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0099 - val_accuracy: 0.9976\n",
            "Epoch 89/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0114 - val_accuracy: 0.9970\n",
            "Epoch 90/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0118 - val_accuracy: 0.9971\n",
            "Epoch 91/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0111 - val_accuracy: 0.9972\n",
            "Epoch 92/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0105 - val_accuracy: 0.9974\n",
            "Epoch 93/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0101 - val_accuracy: 0.9975\n",
            "Epoch 94/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0113 - val_accuracy: 0.9974\n",
            "Epoch 95/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0113 - val_accuracy: 0.9971\n",
            "Epoch 96/500\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0107 - val_accuracy: 0.9972\n",
            "Epoch 97/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0109 - val_accuracy: 0.9973\n",
            "Epoch 98/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0094 - val_accuracy: 0.9976\n",
            "Epoch 99/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0092 - val_accuracy: 0.9975\n",
            "Epoch 100/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.0093 - val_accuracy: 0.9974\n",
            "Epoch 101/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0094 - val_accuracy: 0.9975\n",
            "Epoch 102/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0092 - val_accuracy: 0.9976\n",
            "Epoch 103/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0095 - val_accuracy: 0.9974\n",
            "Epoch 104/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0090 - val_accuracy: 0.9975\n",
            "Epoch 105/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9981 - val_loss: 0.0087 - val_accuracy: 0.9977\n",
            "Epoch 106/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0090 - val_accuracy: 0.9974\n",
            "Epoch 107/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0082 - val_accuracy: 0.9978\n",
            "Epoch 108/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0088 - val_accuracy: 0.9975\n",
            "Epoch 109/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0093 - val_accuracy: 0.9974\n",
            "Epoch 110/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0088 - val_accuracy: 0.9975\n",
            "Epoch 111/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0107 - val_accuracy: 0.9977\n",
            "Epoch 112/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0102 - val_accuracy: 0.9974\n",
            "Epoch 113/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0092 - val_accuracy: 0.9975\n",
            "Epoch 114/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.9982 - val_loss: 0.0082 - val_accuracy: 0.9980\n",
            "Epoch 115/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0086 - val_accuracy: 0.9977\n",
            "Epoch 116/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0087 - val_accuracy: 0.9978\n",
            "Epoch 117/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0094 - val_accuracy: 0.9979\n",
            "Epoch 118/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0083 - val_accuracy: 0.9979\n",
            "Epoch 119/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
            "Epoch 120/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
            "Epoch 121/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.0084 - val_accuracy: 0.9978\n",
            "Epoch 122/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
            "Epoch 123/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.0082 - val_accuracy: 0.9978\n",
            "Epoch 124/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 0.0079 - val_accuracy: 0.9979\n",
            "Epoch 125/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0081 - val_accuracy: 0.9978\n",
            "Epoch 126/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.0080 - val_accuracy: 0.9978\n",
            "Epoch 127/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.0083 - val_accuracy: 0.9978\n",
            "Epoch 128/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
            "Epoch 129/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
            "Epoch 130/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 0.0068 - val_accuracy: 0.9984\n",
            "Epoch 131/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
            "Epoch 132/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0078 - val_accuracy: 0.9980\n",
            "Epoch 133/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
            "Epoch 134/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
            "Epoch 135/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
            "Epoch 136/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0074 - val_accuracy: 0.9982\n",
            "Epoch 137/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
            "Epoch 138/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
            "Epoch 139/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
            "Epoch 140/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0069 - val_accuracy: 0.9984\n",
            "Epoch 141/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0071 - val_accuracy: 0.9984\n",
            "Epoch 142/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0077 - val_accuracy: 0.9981\n",
            "Epoch 143/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.0077 - val_accuracy: 0.9981\n",
            "Epoch 144/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
            "Epoch 145/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0073 - val_accuracy: 0.9985\n",
            "Epoch 146/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0072 - val_accuracy: 0.9984\n",
            "Epoch 147/500\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0066 - val_accuracy: 0.9986\n",
            "Epoch 148/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0066 - val_accuracy: 0.9986\n",
            "Epoch 149/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0066 - val_accuracy: 0.9985\n",
            "Epoch 150/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0067 - val_accuracy: 0.9985\n",
            "Epoch 151/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.0065 - val_accuracy: 0.9986\n",
            "Epoch 152/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0065 - val_accuracy: 0.9986\n",
            "Epoch 153/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0065 - val_accuracy: 0.9986\n",
            "Epoch 154/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0070 - val_accuracy: 0.9985\n",
            "Epoch 155/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.0071 - val_accuracy: 0.9986\n",
            "Epoch 156/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0067 - val_accuracy: 0.9985\n",
            "Epoch 157/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0065 - val_accuracy: 0.9986\n",
            "Epoch 158/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0074 - val_accuracy: 0.9985\n",
            "Epoch 159/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0076 - val_accuracy: 0.9984\n",
            "Epoch 160/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0065 - val_accuracy: 0.9987\n",
            "Epoch 161/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0066 - val_accuracy: 0.9986\n",
            "Epoch 162/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
            "Epoch 163/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
            "Epoch 164/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
            "Epoch 165/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9989\n",
            "Epoch 166/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0086 - val_accuracy: 0.9985\n",
            "Epoch 167/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0062 - val_accuracy: 0.9988\n",
            "Epoch 168/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 0.9988\n",
            "Epoch 169/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9988\n",
            "Epoch 170/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
            "Epoch 171/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0068 - val_accuracy: 0.9986\n",
            "Epoch 172/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
            "Epoch 173/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0091 - val_accuracy: 0.9983\n",
            "Epoch 174/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0068 - val_accuracy: 0.9987\n",
            "Epoch 175/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0058 - val_accuracy: 0.9990\n",
            "Epoch 176/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9988\n",
            "Epoch 177/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
            "Epoch 178/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0064 - val_accuracy: 0.9987\n",
            "Epoch 179/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
            "Epoch 180/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9989\n",
            "Epoch 181/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.0059 - val_accuracy: 0.9989\n",
            "Epoch 182/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.0063 - val_accuracy: 0.9988\n",
            "Epoch 183/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
            "Epoch 184/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
            "Epoch 185/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.0062 - val_accuracy: 0.9989\n",
            "Epoch 186/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0060 - val_accuracy: 0.9989\n",
            "Epoch 187/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0057 - val_accuracy: 0.9990\n",
            "Epoch 188/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0061 - val_accuracy: 0.9990\n",
            "Epoch 189/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0063 - val_accuracy: 0.9989\n",
            "Epoch 190/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.0065 - val_accuracy: 0.9989\n",
            "Epoch 191/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0076 - val_accuracy: 0.9984\n",
            "Epoch 192/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0062 - val_accuracy: 0.9990\n",
            "Epoch 193/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0090 - val_accuracy: 0.9988\n",
            "Epoch 194/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0074 - val_accuracy: 0.9990\n",
            "Epoch 195/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0063 - val_accuracy: 0.9989\n",
            "Epoch 196/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9990\n",
            "Epoch 197/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9989\n",
            "Epoch 198/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9990\n",
            "Epoch 199/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.0062 - val_accuracy: 0.9989\n",
            "Epoch 200/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9989\n",
            "Epoch 201/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9990\n",
            "Epoch 202/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0058 - val_accuracy: 0.9991\n",
            "Epoch 203/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
            "Epoch 204/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0059 - val_accuracy: 0.9991\n",
            "Epoch 205/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0061 - val_accuracy: 0.9990\n",
            "Epoch 206/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0064 - val_accuracy: 0.9989\n",
            "Epoch 207/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0058 - val_accuracy: 0.9991\n",
            "Epoch 208/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0073 - val_accuracy: 0.9989\n",
            "Epoch 209/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0060 - val_accuracy: 0.9991\n",
            "Epoch 210/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0109 - val_accuracy: 0.9991\n",
            "Epoch 211/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.0086 - val_accuracy: 0.9990\n",
            "Epoch 212/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 0.9990 - val_loss: 0.0170 - val_accuracy: 0.9983\n",
            "Epoch 213/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9990 - val_loss: 0.0162 - val_accuracy: 0.9984\n",
            "Epoch 214/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.0139 - val_accuracy: 0.9990\n",
            "Epoch 215/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.0128 - val_accuracy: 0.9990\n",
            "Epoch 216/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 0.0115 - val_accuracy: 0.9990\n",
            "Epoch 217/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0102 - val_accuracy: 0.9990\n",
            "Epoch 218/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0086 - val_accuracy: 0.9990\n",
            "Epoch 219/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0077 - val_accuracy: 0.9990\n",
            "Epoch 220/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0076 - val_accuracy: 0.9989\n",
            "Epoch 221/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0069 - val_accuracy: 0.9992\n",
            "Epoch 222/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0067 - val_accuracy: 0.9990\n",
            "Epoch 223/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0065 - val_accuracy: 0.9991\n",
            "Epoch 224/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0064 - val_accuracy: 0.9991\n",
            "Epoch 225/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0063 - val_accuracy: 0.9991\n",
            "Epoch 226/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 227/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 228/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0067 - val_accuracy: 0.9990\n",
            "Epoch 229/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0063 - val_accuracy: 0.9991\n",
            "Epoch 230/500\n",
            "39/39 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 231/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 232/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 233/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0065 - val_accuracy: 0.9991\n",
            "Epoch 234/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0062 - val_accuracy: 0.9991\n",
            "Epoch 235/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 9.8642e-04 - accuracy: 0.9996 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 236/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0065 - val_accuracy: 0.9991\n",
            "Epoch 237/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 238/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 9.7261e-04 - accuracy: 0.9996 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 239/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 9.3985e-04 - accuracy: 0.9996 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
            "Epoch 240/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 9.3871e-04 - accuracy: 0.9996 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 241/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 9.3299e-04 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 242/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 9.1012e-04 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 243/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 9.1422e-04 - accuracy: 0.9996 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 244/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 8.7737e-04 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 245/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 9.0245e-04 - accuracy: 0.9996 - val_loss: 0.0063 - val_accuracy: 0.9991\n",
            "Epoch 246/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.7466e-04 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 247/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 8.5386e-04 - accuracy: 0.9996 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 248/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.5745e-04 - accuracy: 0.9996 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 249/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.3860e-04 - accuracy: 0.9996 - val_loss: 0.0060 - val_accuracy: 0.9993\n",
            "Epoch 250/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.3343e-04 - accuracy: 0.9996 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
            "Epoch 251/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.5641e-04 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 252/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 8.2002e-04 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9992\n",
            "Epoch 253/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 8.5294e-04 - accuracy: 0.9996 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 254/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.1121e-04 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 255/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 8.2428e-04 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9993\n",
            "Epoch 256/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.5578e-04 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
            "Epoch 257/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 7.9215e-04 - accuracy: 0.9996 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 258/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.5257e-04 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 259/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.1132e-04 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
            "Epoch 260/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.7724e-04 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
            "Epoch 261/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 7.7310e-04 - accuracy: 0.9996 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
            "Epoch 262/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.5381e-04 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
            "Epoch 263/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 7.5824e-04 - accuracy: 0.9996 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
            "Epoch 264/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 8.0579e-04 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9991\n",
            "Epoch 265/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 7.5673e-04 - accuracy: 0.9996 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
            "Epoch 266/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.3494e-04 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
            "Epoch 267/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 7.2145e-04 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
            "Epoch 268/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.0633e-04 - accuracy: 0.9996 - val_loss: 0.0064 - val_accuracy: 0.9993\n",
            "Epoch 269/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.0787e-04 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 270/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.9657e-04 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
            "Epoch 271/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.2795e-04 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9992\n",
            "Epoch 272/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 7.4175e-04 - accuracy: 0.9996 - val_loss: 0.0065 - val_accuracy: 0.9993\n",
            "Epoch 273/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.6855e-04 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 274/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.7807e-04 - accuracy: 0.9996 - val_loss: 0.0063 - val_accuracy: 0.9993\n",
            "Epoch 275/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.2354e-04 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 276/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.7148e-04 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
            "Epoch 277/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.6831e-04 - accuracy: 0.9996 - val_loss: 0.0066 - val_accuracy: 0.9993\n",
            "Epoch 278/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0074 - val_accuracy: 0.9992\n",
            "Epoch 279/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0095 - val_accuracy: 0.9990\n",
            "Epoch 280/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0095 - val_accuracy: 0.9992\n",
            "Epoch 281/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
            "Epoch 282/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 8.7281e-04 - accuracy: 0.9996 - val_loss: 0.0069 - val_accuracy: 0.9992\n",
            "Epoch 283/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.8925e-04 - accuracy: 0.9997 - val_loss: 0.0067 - val_accuracy: 0.9992\n",
            "Epoch 284/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.0176e-04 - accuracy: 0.9997 - val_loss: 0.0067 - val_accuracy: 0.9992\n",
            "Epoch 285/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 7.5106e-04 - accuracy: 0.9996 - val_loss: 0.0069 - val_accuracy: 0.9992\n",
            "Epoch 286/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.2453e-04 - accuracy: 0.9996 - val_loss: 0.0068 - val_accuracy: 0.9993\n",
            "Epoch 287/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.2205e-04 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9993\n",
            "Epoch 288/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.0797e-04 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9993\n",
            "Epoch 289/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.2616e-04 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9993\n",
            "Epoch 290/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.8347e-04 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9993\n",
            "Epoch 291/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.8506e-04 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9993\n",
            "Epoch 292/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.9866e-04 - accuracy: 0.9996 - val_loss: 0.0068 - val_accuracy: 0.9993\n",
            "Epoch 293/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 6.3540e-04 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9992\n",
            "Epoch 294/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.8854e-04 - accuracy: 0.9997 - val_loss: 0.0070 - val_accuracy: 0.9993\n",
            "Epoch 295/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.6752e-04 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9992\n",
            "Epoch 296/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.8145e-04 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9993\n",
            "Epoch 297/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.7342e-04 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9993\n",
            "Epoch 298/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.7551e-04 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9993\n",
            "Epoch 299/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.4795e-04 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9993\n",
            "Epoch 300/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.4526e-04 - accuracy: 0.9997 - val_loss: 0.0070 - val_accuracy: 0.9993\n",
            "Epoch 301/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.6372e-04 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9992\n",
            "Epoch 302/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.8195e-04 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 303/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.2323e-04 - accuracy: 0.9997 - val_loss: 0.0070 - val_accuracy: 0.9993\n",
            "Epoch 304/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.7417e-04 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9993\n",
            "Epoch 305/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.2488e-04 - accuracy: 0.9997 - val_loss: 0.0072 - val_accuracy: 0.9993\n",
            "Epoch 306/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.7751e-04 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
            "Epoch 307/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.4876e-04 - accuracy: 0.9997 - val_loss: 0.0070 - val_accuracy: 0.9993\n",
            "Epoch 308/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.2744e-04 - accuracy: 0.9997 - val_loss: 0.0073 - val_accuracy: 0.9992\n",
            "Epoch 309/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 6.4127e-04 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 0.9993\n",
            "Epoch 310/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.1076e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9993\n",
            "Epoch 311/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.3500e-04 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
            "Epoch 312/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.2554e-04 - accuracy: 0.9997 - val_loss: 0.0072 - val_accuracy: 0.9993\n",
            "Epoch 313/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.0515e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9993\n",
            "Epoch 314/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.9803e-04 - accuracy: 0.9997 - val_loss: 0.0073 - val_accuracy: 0.9993\n",
            "Epoch 315/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.7970e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9993\n",
            "Epoch 316/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.1692e-04 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9993\n",
            "Epoch 317/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.7600e-04 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9993\n",
            "Epoch 318/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.0141e-04 - accuracy: 0.9997 - val_loss: 0.0072 - val_accuracy: 0.9993\n",
            "Epoch 319/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.7427e-04 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9993\n",
            "Epoch 320/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.0299e-04 - accuracy: 0.9998 - val_loss: 0.0074 - val_accuracy: 0.9992\n",
            "Epoch 321/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.2046e-04 - accuracy: 0.9998 - val_loss: 0.0075 - val_accuracy: 0.9993\n",
            "Epoch 322/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 4.5732e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9993\n",
            "Epoch 323/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.0801e-04 - accuracy: 0.9998 - val_loss: 0.0075 - val_accuracy: 0.9992\n",
            "Epoch 324/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.3895e-04 - accuracy: 0.9998 - val_loss: 0.0075 - val_accuracy: 0.9994\n",
            "Epoch 325/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.3418e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9993\n",
            "Epoch 326/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.4840e-04 - accuracy: 0.9998 - val_loss: 0.0076 - val_accuracy: 0.9993\n",
            "Epoch 327/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.8768e-04 - accuracy: 0.9998 - val_loss: 0.0075 - val_accuracy: 0.9993\n",
            "Epoch 328/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.8061e-04 - accuracy: 0.9998 - val_loss: 0.0077 - val_accuracy: 0.9993\n",
            "Epoch 329/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 4.3534e-04 - accuracy: 0.9998 - val_loss: 0.0077 - val_accuracy: 0.9993\n",
            "Epoch 330/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.8319e-04 - accuracy: 0.9998 - val_loss: 0.0076 - val_accuracy: 0.9992\n",
            "Epoch 331/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.9415e-04 - accuracy: 0.9997 - val_loss: 0.0079 - val_accuracy: 0.9993\n",
            "Epoch 332/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.3843e-04 - accuracy: 0.9998 - val_loss: 0.0077 - val_accuracy: 0.9993\n",
            "Epoch 333/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.1756e-04 - accuracy: 0.9998 - val_loss: 0.0076 - val_accuracy: 0.9993\n",
            "Epoch 334/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.3838e-04 - accuracy: 0.9998 - val_loss: 0.0077 - val_accuracy: 0.9994\n",
            "Epoch 335/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 8.0910e-04 - accuracy: 0.9997 - val_loss: 0.0078 - val_accuracy: 0.9993\n",
            "Epoch 336/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 8.6205e-04 - accuracy: 0.9997 - val_loss: 0.0076 - val_accuracy: 0.9993\n",
            "Epoch 337/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.2368e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9993\n",
            "Epoch 338/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.1948e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9993\n",
            "Epoch 339/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.2864e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9993\n",
            "Epoch 340/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.4624e-04 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 0.9992\n",
            "Epoch 341/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.9785e-04 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9993\n",
            "Epoch 342/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.2299e-04 - accuracy: 0.9998 - val_loss: 0.0080 - val_accuracy: 0.9993\n",
            "Epoch 343/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.3929e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9993\n",
            "Epoch 344/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.6069e-04 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9993\n",
            "Epoch 345/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.5522e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9993\n",
            "Epoch 346/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.4044e-04 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9993\n",
            "Epoch 347/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0086 - val_accuracy: 0.9992\n",
            "Epoch 348/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0120 - val_accuracy: 0.9992\n",
            "Epoch 349/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0088 - val_accuracy: 0.9993\n",
            "Epoch 350/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0085 - val_accuracy: 0.9993\n",
            "Epoch 351/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 7.2587e-04 - accuracy: 0.9998 - val_loss: 0.0083 - val_accuracy: 0.9992\n",
            "Epoch 352/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.5497e-04 - accuracy: 0.9997 - val_loss: 0.0084 - val_accuracy: 0.9992\n",
            "Epoch 353/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.5971e-04 - accuracy: 0.9998 - val_loss: 0.0083 - val_accuracy: 0.9993\n",
            "Epoch 354/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.2102e-04 - accuracy: 0.9998 - val_loss: 0.0083 - val_accuracy: 0.9993\n",
            "Epoch 355/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.1971e-04 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 0.9993\n",
            "Epoch 356/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.2002e-04 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 0.9993\n",
            "Epoch 357/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.8522e-04 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
            "Epoch 358/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.0533e-04 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
            "Epoch 359/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.1890e-04 - accuracy: 0.9999 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
            "Epoch 360/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.1814e-04 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
            "Epoch 361/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.6920e-04 - accuracy: 0.9998 - val_loss: 0.0085 - val_accuracy: 0.9993\n",
            "Epoch 362/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.6897e-04 - accuracy: 0.9998 - val_loss: 0.0082 - val_accuracy: 0.9993\n",
            "Epoch 363/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.1826e-04 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
            "Epoch 364/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.3578e-04 - accuracy: 0.9999 - val_loss: 0.0086 - val_accuracy: 0.9993\n",
            "Epoch 365/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.6931e-04 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9993\n",
            "Epoch 366/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.3095e-04 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
            "Epoch 367/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.8802e-04 - accuracy: 0.9998 - val_loss: 0.0087 - val_accuracy: 0.9993\n",
            "Epoch 368/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.3699e-04 - accuracy: 0.9999 - val_loss: 0.0086 - val_accuracy: 0.9993\n",
            "Epoch 369/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.6568e-04 - accuracy: 0.9998 - val_loss: 0.0094 - val_accuracy: 0.9992\n",
            "Epoch 370/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 9.7838e-04 - accuracy: 0.9997 - val_loss: 0.0090 - val_accuracy: 0.9993\n",
            "Epoch 371/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.5890e-04 - accuracy: 0.9999 - val_loss: 0.0087 - val_accuracy: 0.9993\n",
            "Epoch 372/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.6827e-04 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9993\n",
            "Epoch 373/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.7674e-04 - accuracy: 0.9998 - val_loss: 0.0088 - val_accuracy: 0.9993\n",
            "Epoch 374/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.8294e-04 - accuracy: 0.9998 - val_loss: 0.0088 - val_accuracy: 0.9993\n",
            "Epoch 375/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.8179e-04 - accuracy: 0.9998 - val_loss: 0.0088 - val_accuracy: 0.9993\n",
            "Epoch 376/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.4871e-04 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9993\n",
            "Epoch 377/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 6.3524e-04 - accuracy: 0.9998 - val_loss: 0.0095 - val_accuracy: 0.9992\n",
            "Epoch 378/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 7.8447e-04 - accuracy: 0.9998 - val_loss: 0.0093 - val_accuracy: 0.9993\n",
            "Epoch 379/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.2153e-04 - accuracy: 0.9998 - val_loss: 0.0087 - val_accuracy: 0.9993\n",
            "Epoch 380/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.7348e-04 - accuracy: 0.9998 - val_loss: 0.0088 - val_accuracy: 0.9993\n",
            "Epoch 381/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 7.4118e-04 - accuracy: 0.9998 - val_loss: 0.0092 - val_accuracy: 0.9993\n",
            "Epoch 382/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.3247e-04 - accuracy: 0.9998 - val_loss: 0.0089 - val_accuracy: 0.9993\n",
            "Epoch 383/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.4052e-04 - accuracy: 0.9999 - val_loss: 0.0089 - val_accuracy: 0.9993\n",
            "Epoch 384/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.6355e-04 - accuracy: 0.9999 - val_loss: 0.0088 - val_accuracy: 0.9992\n",
            "Epoch 385/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 4.2048e-04 - accuracy: 0.9998 - val_loss: 0.0091 - val_accuracy: 0.9993\n",
            "Epoch 386/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.9154e-04 - accuracy: 0.9999 - val_loss: 0.0091 - val_accuracy: 0.9992\n",
            "Epoch 387/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.3400e-04 - accuracy: 0.9998 - val_loss: 0.0092 - val_accuracy: 0.9993\n",
            "Epoch 388/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.0618e-04 - accuracy: 0.9998 - val_loss: 0.0090 - val_accuracy: 0.9993\n",
            "Epoch 389/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.4319e-04 - accuracy: 0.9998 - val_loss: 0.0091 - val_accuracy: 0.9993\n",
            "Epoch 390/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.0823e-04 - accuracy: 0.9999 - val_loss: 0.0091 - val_accuracy: 0.9993\n",
            "Epoch 391/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 3.2202e-04 - accuracy: 0.9998 - val_loss: 0.0089 - val_accuracy: 0.9993\n",
            "Epoch 392/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.9229e-04 - accuracy: 0.9998 - val_loss: 0.0092 - val_accuracy: 0.9993\n",
            "Epoch 393/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.4511e-04 - accuracy: 0.9998 - val_loss: 0.0090 - val_accuracy: 0.9992\n",
            "Epoch 394/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.8825e-04 - accuracy: 0.9998 - val_loss: 0.0091 - val_accuracy: 0.9993\n",
            "Epoch 395/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.0462e-04 - accuracy: 0.9999 - val_loss: 0.0091 - val_accuracy: 0.9993\n",
            "Epoch 396/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.2516e-04 - accuracy: 0.9998 - val_loss: 0.0094 - val_accuracy: 0.9993\n",
            "Epoch 397/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.9397e-04 - accuracy: 0.9998 - val_loss: 0.0109 - val_accuracy: 0.9993\n",
            "Epoch 398/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0097 - val_accuracy: 0.9993\n",
            "Epoch 399/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.9609e-04 - accuracy: 0.9998 - val_loss: 0.0095 - val_accuracy: 0.9993\n",
            "Epoch 400/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0125 - val_accuracy: 0.9992\n",
            "Epoch 401/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0117 - val_accuracy: 0.9993\n",
            "Epoch 402/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0114 - val_accuracy: 0.9992\n",
            "Epoch 403/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0116 - val_accuracy: 0.9992\n",
            "Epoch 404/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0111 - val_accuracy: 0.9992\n",
            "Epoch 405/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.4902e-04 - accuracy: 0.9998 - val_loss: 0.0106 - val_accuracy: 0.9992\n",
            "Epoch 406/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0115 - val_accuracy: 0.9992\n",
            "Epoch 407/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0109 - val_accuracy: 0.9992\n",
            "Epoch 408/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 6.8646e-04 - accuracy: 0.9998 - val_loss: 0.0104 - val_accuracy: 0.9992\n",
            "Epoch 409/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.9919e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9992\n",
            "Epoch 410/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.3450e-04 - accuracy: 0.9998 - val_loss: 0.0097 - val_accuracy: 0.9993\n",
            "Epoch 411/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.0946e-04 - accuracy: 0.9999 - val_loss: 0.0099 - val_accuracy: 0.9993\n",
            "Epoch 412/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0171 - val_accuracy: 0.9992\n",
            "Epoch 413/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.0165 - val_accuracy: 0.9993\n",
            "Epoch 414/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.0147 - val_accuracy: 0.9993\n",
            "Epoch 415/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0133 - val_accuracy: 0.9992\n",
            "Epoch 416/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0092 - accuracy: 0.9994 - val_loss: 0.0189 - val_accuracy: 0.9988\n",
            "Epoch 417/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.0182 - val_accuracy: 0.9988\n",
            "Epoch 418/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.0168 - val_accuracy: 0.9988\n",
            "Epoch 419/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0137 - val_accuracy: 0.9991\n",
            "Epoch 420/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0124 - val_accuracy: 0.9991\n",
            "Epoch 421/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0118 - val_accuracy: 0.9991\n",
            "Epoch 422/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0114 - val_accuracy: 0.9991\n",
            "Epoch 423/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0111 - val_accuracy: 0.9991\n",
            "Epoch 424/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0107 - val_accuracy: 0.9991\n",
            "Epoch 425/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 8.7534e-04 - accuracy: 0.9998 - val_loss: 0.0106 - val_accuracy: 0.9992\n",
            "Epoch 426/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 6.9736e-04 - accuracy: 0.9998 - val_loss: 0.0106 - val_accuracy: 0.9992\n",
            "Epoch 427/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 6.1053e-04 - accuracy: 0.9998 - val_loss: 0.0105 - val_accuracy: 0.9991\n",
            "Epoch 428/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.6236e-04 - accuracy: 0.9998 - val_loss: 0.0104 - val_accuracy: 0.9991\n",
            "Epoch 429/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 5.1112e-04 - accuracy: 0.9999 - val_loss: 0.0104 - val_accuracy: 0.9991\n",
            "Epoch 430/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.7988e-04 - accuracy: 0.9999 - val_loss: 0.0103 - val_accuracy: 0.9992\n",
            "Epoch 431/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.4232e-04 - accuracy: 0.9999 - val_loss: 0.0103 - val_accuracy: 0.9992\n",
            "Epoch 432/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.1825e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9992\n",
            "Epoch 433/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 4.1099e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9992\n",
            "Epoch 434/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.8933e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9992\n",
            "Epoch 435/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.8094e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 436/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.7246e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9992\n",
            "Epoch 437/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 3.6289e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9992\n",
            "Epoch 438/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.5572e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 439/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.4857e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 440/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.3731e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9992\n",
            "Epoch 441/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.2883e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 442/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.3157e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 443/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.1727e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 444/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.3488e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 445/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.2101e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 446/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.9921e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9992\n",
            "Epoch 447/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.0265e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 448/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.0120e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 449/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.8737e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 450/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.9073e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 451/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.8837e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 452/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.8215e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 453/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.6977e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 454/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.6915e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 455/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.8146e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 456/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.7246e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 457/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.6755e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 458/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.6721e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 459/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.7787e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 460/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.6411e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 461/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.5433e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 462/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.5602e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 463/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.5891e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 464/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.5124e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 465/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.7112e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 466/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.5399e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9992\n",
            "Epoch 467/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.7845e-04 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9993\n",
            "Epoch 468/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 3.9252e-04 - accuracy: 0.9998 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 469/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.9577e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 470/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.8944e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 471/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.5317e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 472/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.4106e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9992\n",
            "Epoch 473/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.5688e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 474/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.5225e-04 - accuracy: 0.9999 - val_loss: 0.0099 - val_accuracy: 0.9993\n",
            "Epoch 475/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.8525e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 476/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.5898e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 477/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.6045e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9993\n",
            "Epoch 478/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.4703e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 479/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.3549e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9993\n",
            "Epoch 480/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.7359e-04 - accuracy: 0.9999 - val_loss: 0.0099 - val_accuracy: 0.9993\n",
            "Epoch 481/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.8149e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9993\n",
            "Epoch 482/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.4778e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 483/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.3321e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9993\n",
            "Epoch 484/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.7211e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 485/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.4654e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 486/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.5479e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 487/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.4797e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 488/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.4906e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 489/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.3337e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9993\n",
            "Epoch 490/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.3602e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9993\n",
            "Epoch 491/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.4984e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 492/500\n",
            "39/39 [==============================] - 0s 8ms/step - loss: 2.7758e-04 - accuracy: 0.9998 - val_loss: 0.0102 - val_accuracy: 0.9993\n",
            "Epoch 493/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 2.2495e-04 - accuracy: 0.9999 - val_loss: 0.0103 - val_accuracy: 0.9993\n",
            "Epoch 494/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 5.2014e-04 - accuracy: 0.9998 - val_loss: 0.0106 - val_accuracy: 0.9992\n",
            "Epoch 495/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 6.3286e-04 - accuracy: 0.9998 - val_loss: 0.0103 - val_accuracy: 0.9993\n",
            "Epoch 496/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 7.3337e-04 - accuracy: 0.9998 - val_loss: 0.0101 - val_accuracy: 0.9993\n",
            "Epoch 497/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.2236e-04 - accuracy: 0.9999 - val_loss: 0.0103 - val_accuracy: 0.9993\n",
            "Epoch 498/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 4.7119e-04 - accuracy: 0.9999 - val_loss: 0.0104 - val_accuracy: 0.9993\n",
            "Epoch 499/500\n",
            "39/39 [==============================] - 0s 7ms/step - loss: 3.2228e-04 - accuracy: 0.9999 - val_loss: 0.0102 - val_accuracy: 0.9993\n",
            "Epoch 500/500\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 2.4349e-04 - accuracy: 0.9999 - val_loss: 0.0104 - val_accuracy: 0.9993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model using test dataset\n",
        "loss, accuracy = model.evaluate(x_test_scaled, y_test, batch_size=4096)\n",
        "print('Model Evaluation Accuracy is', f'{accuracy *100:.1f}' , '%')\n",
        "\n",
        "\n",
        "#making training and validation plot\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "epoch_range = np.array(range(EPOCHS))\n",
        "\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=epoch_range, y=history.history['accuracy'], name=\"Training Accuracy\"),\n",
        "\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "   go.Scatter(x=epoch_range, y=history.history['val_accuracy'], name='Validation Acccuracy'),\n",
        "\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=epoch_range, y=history.history['loss'], name='Training Loss'),\n",
        "\n",
        "    row=1, col=2\n",
        ")\n",
        "fig.add_trace(\n",
        "   go.Scatter(x=epoch_range, y=history.history['val_loss'], name='Validation Loss'),\n",
        "\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout( title_text=\"Training and Validation Plot\")\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "Dk76ulGEoPjg",
        "outputId": "02d48d1d-9667-4256-a7d4-7e109af859e4"
      },
      "id": "Dk76ulGEoPjg",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9993\n",
            "Model Evaluation Accuracy is 99.9 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"0b29071d-cf20-4d20-beb2-e941372b2f0f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0b29071d-cf20-4d20-beb2-e941372b2f0f\")) {                    Plotly.newPlot(                        \"0b29071d-cf20-4d20-beb2-e941372b2f0f\",                        [{\"name\":\"Training Accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],\"y\":[0.8953337669372559,0.9849200248718262,0.9876452088356018,0.9864368438720703,0.9898040294647217,0.9882746338844299,0.9854612946510315,0.9899235963821411,0.9871354103088379,0.9862920641899109,0.9902005195617676,0.9870032668113708,0.9884319305419922,0.9891242980957031,0.9899424910545349,0.989520788192749,0.9899802207946777,0.9906788468360901,0.9898921251296997,0.9906725287437439,0.9912075400352478,0.9921767711639404,0.9898102879524231,0.9928376078605652,0.9912641644477844,0.9924474358558655,0.9913396835327148,0.9924789071083069,0.9924411177635193,0.993057906627655,0.9926362037658691,0.992856502532959,0.9931648969650269,0.9921830892562866,0.9941341876983643,0.993171215057373,0.9933915138244629,0.9935740232467651,0.9942663311958313,0.993655800819397,0.9936180710792542,0.9942600131034851,0.9941278696060181,0.9950845241546631,0.9936243891716003,0.9948894381523132,0.994927167892456,0.9950845241546631,0.9948201775550842,0.9952104091644287,0.99543696641922,0.9950782060623169,0.9953740239143372,0.9956257939338684,0.9957202076911926,0.9949901103973389,0.9960600733757019,0.9959845542907715,0.9958712458610535,0.9959027171134949,0.9958712458610535,0.9966264963150024,0.9958208799362183,0.9964250922203064,0.9965320825576782,0.996374785900116,0.9967523813247681,0.9964817762374878,0.9970545172691345,0.9961292743682861,0.9968971610069275,0.9969601035118103,0.9970545172691345,0.9970481991767883,0.9970356225967407,0.997148871421814,0.9972118139266968,0.9974006414413452,0.9972244501113892,0.9973188042640686,0.9974761605262756,0.997507631778717,0.997507631778717,0.9974321126937866,0.9975705742835999,0.9975894689559937,0.9975139498710632,0.9975454211235046,0.9978600740432739,0.9976901412010193,0.9977342486381531,0.9978160262107849,0.9978600740432739,0.9977782964706421,0.9979041814804077,0.9979608058929443,0.9979104399681091,0.9978852868080139,0.9980552196502686,0.9979419112205505,0.9980929493904114,0.9980111718177795,0.9981118440628052,0.9981684684753418,0.9980677962303162,0.998244047164917,0.9981622099876404,0.9982062578201294,0.9982817769050598,0.9983132481575012,0.9981496334075928,0.9983384609222412,0.9983636140823364,0.9981622099876404,0.9984328150749207,0.9984265565872192,0.9983510375022888,0.9984769225120544,0.9985146522521973,0.998445451259613,0.9984831809997559,0.9985587000846863,0.9985398054122925,0.9985398054122925,0.9985964894294739,0.9986342191696167,0.9986405372619629,0.9986656904220581,0.9987349510192871,0.9985146522521973,0.9987601041793823,0.9987726807594299,0.9986971616744995,0.9986468553543091,0.9988356232643127,0.9988608360290527,0.9988923072814941,0.9988923072814941,0.998930037021637,0.9989237785339355,0.9988167881965637,0.9989426136016846,0.9989174604415894,0.9988608360290527,0.9988796710968018,0.998974084854126,0.9990244507789612,0.9990559220314026,0.9990559220314026,0.9990684986114502,0.9990370273590088,0.9990999698638916,0.9990937113761902,0.9990999698638916,0.9990181922912598,0.999087393283844,0.9991503357887268,0.9990118741989136,0.999043345451355,0.9991692304611206,0.9991503357887268,0.9991629123687744,0.9991440176963806,0.9991943836212158,0.999200701713562,0.9991692304611206,0.9990810751914978,0.9992132782936096,0.9991503357887268,0.9992069602012634,0.9992762207984924,0.999200701713562,0.9991881251335144,0.9990937113761902,0.9992573261260986,0.9992573261260986,0.9993013739585876,0.9993265867233276,0.99928879737854,0.9993013739585876,0.9993265867233276,0.9993265867233276,0.9993013739585876,0.9993139505386353,0.9993391633033752,0.9993139505386353,0.999358057975769,0.9992824792861938,0.9993768930435181,0.9993265867233276,0.9993894696235657,0.9991818070411682,0.9993517398834229,0.9992069602012634,0.9993706345558167,0.9994021058082581,0.9994272589683533,0.9993832111358643,0.9994272589683533,0.9994461536407471,0.9994650483131409,0.9994776248931885,0.9994587302207947,0.9994146823883057,0.9994587302207947,0.9994335770606995,0.9994713068008423,0.9994838833808899,0.9993832111358643,0.9992258548736572,0.9992762207984924,0.998999297618866,0.9990118741989136,0.999200701713562,0.9992636442184448,0.9992699027061462,0.9993013739585876,0.9993894696235657,0.9993768930435181,0.9994587302207947,0.9993957877159119,0.9994776248931885,0.9994713068008423,0.9995153546333313,0.9994587302207947,0.9994713068008423,0.9995153546333313,0.9995279908180237,0.9994776248931885,0.9995216727256775,0.9995468258857727,0.9994902014732361,0.9995468258857727,0.9994902014732361,0.9995531439781189,0.9995846152305603,0.9994965195655823,0.9995657205581665,0.9995657205581665,0.9995782971382141,0.9995846152305603,0.9995531439781189,0.9995971918106079,0.9995782971382141,0.9996223449707031,0.9995657205581665,0.9995971918106079,0.9995908737182617,0.9996097683906555,0.9995971918106079,0.9996160864830017,0.9995971918106079,0.9996035099029541,0.9996035099029541,0.9995846152305603,0.9995846152305603,0.9996286630630493,0.9996349811553955,0.9995846152305603,0.9996097683906555,0.9996286630630493,0.9996223449707031,0.9996412396430969,0.9996097683906555,0.9996160864830017,0.9996223449707031,0.9996538162231445,0.9996286630630493,0.9996601343154907,0.9996601343154907,0.9996475577354431,0.9996286630630493,0.9996538162231445,0.9996475577354431,0.9996727108955383,0.9996538162231445,0.9996349811553955,0.9995782971382141,0.9995468258857727,0.9994021058082581,0.9994713068008423,0.9996035099029541,0.9996601343154907,0.9996790289878845,0.9996475577354431,0.9996349811553955,0.9996727108955383,0.9996601343154907,0.9996979236602783,0.9996852874755859,0.9996852874755859,0.9996286630630493,0.9997041821479797,0.9997167587280273,0.9996979236602783,0.9996916055679321,0.9996852874755859,0.9997167587280273,0.9997167587280273,0.9996979236602783,0.9996916055679321,0.9996916055679321,0.9997041821479797,0.9997230768203735,0.9997482299804688,0.9997230768203735,0.9997105002403259,0.9996916055679321,0.9997105002403259,0.9997671246528625,0.9996852874755859,0.9997293949127197,0.9997860193252563,0.9997419714927673,0.9997545480728149,0.9997860193252563,0.9997797012329102,0.9997482299804688,0.9997860193252563,0.9997734427452087,0.9997608065605164,0.9997860193252563,0.9997922778129578,0.9997671246528625,0.9997860193252563,0.9997860193252563,0.9997922778129578,0.9997608065605164,0.9998049139976501,0.9998111724853516,0.9997419714927673,0.9997860193252563,0.9997922778129578,0.9997922778129578,0.9996979236602783,0.9996790289878845,0.9997608065605164,0.9998300671577454,0.9998049139976501,0.9997922778129578,0.9997671246528625,0.9998237490653992,0.9998237490653992,0.9997860193252563,0.9998174905776978,0.999842643737793,0.9996412396430969,0.9995720386505127,0.9995657205581665,0.9996790289878845,0.9997608065605164,0.9997419714927673,0.9997671246528625,0.9998111724853516,0.9998174905776978,0.9998363852500916,0.9998363852500916,0.9998111724853516,0.9998741149902344,0.9998174905776978,0.9998489618301392,0.9998363852500916,0.999842643737793,0.9998552203178406,0.9998300671577454,0.9998363852500916,0.9998489618301392,0.9998552203178406,0.9998049139976501,0.9997293949127197,0.9998552203178406,0.999842643737793,0.9998363852500916,0.9998489618301392,0.9998300671577454,0.9998300671577454,0.9998174905776978,0.9997608065605164,0.9998049139976501,0.9998363852500916,0.9997734427452087,0.9998363852500916,0.9998741149902344,0.9998615384101868,0.999842643737793,0.9998741149902344,0.9998049139976501,0.9998300671577454,0.999842643737793,0.999867856502533,0.999842643737793,0.999842643737793,0.9997922778129578,0.9998489618301392,0.999867856502533,0.999842643737793,0.9998237490653992,0.9997419714927673,0.999842643737793,0.9996916055679321,0.9997608065605164,0.999798595905304,0.9996790289878845,0.9997608065605164,0.9998363852500916,0.9997734427452087,0.9997860193252563,0.999842643737793,0.999867856502533,0.999842643737793,0.999867856502533,0.9997608065605164,0.9995342493057251,0.9996538162231445,0.9996727108955383,0.9994083642959595,0.999175488948822,0.9992510080337524,0.9994838833808899,0.9996538162231445,0.9996979236602783,0.9997545480728149,0.9997797012329102,0.9997734427452087,0.999798595905304,0.9998363852500916,0.9998489618301392,0.999842643737793,0.9998615384101868,0.9998615384101868,0.999867856502533,0.9998741149902344,0.999867856502533,0.9998615384101868,0.999886691570282,0.9998804330825806,0.999867856502533,0.9998741149902344,0.999867856502533,0.999886691570282,0.9998993277549744,0.9998993277549744,0.9998804330825806,0.999886691570282,0.9998930096626282,0.9998930096626282,0.9998930096626282,0.999886691570282,0.999886691570282,0.999886691570282,0.9998930096626282,0.999886691570282,0.9998930096626282,0.9998930096626282,0.9999055862426758,0.9998804330825806,0.9998804330825806,0.9999055862426758,0.9998930096626282,0.999886691570282,0.9998993277549744,0.9998993277549744,0.9998993277549744,0.999886691570282,0.9998993277549744,0.9998741149902344,0.9998993277549744,0.999842643737793,0.999886691570282,0.9998804330825806,0.9998930096626282,0.9998930096626282,0.9998804330825806,0.9998993277549744,0.999886691570282,0.9998804330825806,0.9998993277549744,0.9998930096626282,0.9998930096626282,0.9998993277549744,0.999886691570282,0.9998930096626282,0.9998930096626282,0.999886691570282,0.9998930096626282,0.999886691570282,0.9998930096626282,0.999886691570282,0.9998993277549744,0.9998930096626282,0.9999055862426758,0.9998489618301392,0.9998930096626282,0.9998300671577454,0.9998300671577454,0.9997797012329102,0.999886691570282,0.9998804330825806,0.999886691570282,0.9998804330825806],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Validation Acccuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],\"y\":[0.9856502413749695,0.9858768582344055,0.9849957227706909,0.9882181286811829,0.986883819103241,0.9863803386688232,0.9883943200111389,0.985927164554596,0.9874880313873291,0.988041877746582,0.9864054918289185,0.9881677627563477,0.9874880313873291,0.9890740513801575,0.9887216091156006,0.9894768595695496,0.9901817440986633,0.9890740513801575,0.990710437297821,0.9910628795623779,0.9906097650527954,0.9899551868438721,0.9923216104507446,0.9899048209190369,0.99146568775177,0.9915160536766052,0.9927999377250671,0.9920950531959534,0.9920446872711182,0.9927999377250671,0.9921957850456238,0.9927244186401367,0.9916419386863708,0.9943859577178955,0.9923971891403198,0.9938573241233826,0.9942349195480347,0.9936307072639465,0.9920446872711182,0.993932843208313,0.9938069581985474,0.9940335154533386,0.9944866895675659,0.9937818050384521,0.9953174591064453,0.9933034777641296,0.9949901700019836,0.9943608045578003,0.9944615364074707,0.9942097663879395,0.9942349195480347,0.9949146509170532,0.994134247303009,0.9957202672958374,0.9941845536231995,0.995820939540863,0.9952923059463501,0.9953174591064453,0.9950405359268188,0.9955440163612366,0.9960978627204895,0.9957706332206726,0.996374785900116,0.9957202672958374,0.9960475564002991,0.9964503049850464,0.9957202672958374,0.9961230754852295,0.995619535446167,0.9967272281646729,0.9968783259391785,0.9963244795799255,0.9965510368347168,0.9965258836746216,0.9968279600143433,0.9969034790992737,0.996601402759552,0.9968531131744385,0.9969538450241089,0.9970041513442993,0.9970293641090393,0.9966517090797424,0.9970545172691345,0.9973818063735962,0.997356653213501,0.9973818063735962,0.9974069595336914,0.997558057308197,0.9970041513442993,0.9970545172691345,0.9971804022789001,0.9973818063735962,0.9974824786186218,0.997356653213501,0.9970545172691345,0.9972307682037354,0.9972810745239258,0.9975832104682922,0.9974824786186218,0.9974321722984314,0.9975076913833618,0.9975832104682922,0.9973818063735962,0.997532844543457,0.9976838827133179,0.9974321722984314,0.9977846145629883,0.9975076913833618,0.9974321722984314,0.9975076913833618,0.9976587295532227,0.9974321722984314,0.9975076913833618,0.9980111718177795,0.9976838827133179,0.9977846145629883,0.9979356527328491,0.9978852868080139,0.9979104995727539,0.9980615377426147,0.9978097677230835,0.9977846145629883,0.9978349804878235,0.9978601336479187,0.9978097677230835,0.9978349804878235,0.9977846145629883,0.9983384609222412,0.9981622099876404,0.9983636140823364,0.9980111718177795,0.9980363249778748,0.9982629418373108,0.9981622099876404,0.9983888268470764,0.9982125759124756,0.998288094997406,0.9984139800071716,0.9984391331672668,0.9983888268470764,0.9983888268470764,0.99808669090271,0.99811190366745,0.9979608058929443,0.998489499092102,0.9983888268470764,0.9985650181770325,0.9985650181770325,0.9985398650169373,0.9985398650169373,0.9985650181770325,0.9986153841018677,0.9985650181770325,0.998489499092102,0.9985902309417725,0.9985398650169373,0.9986153841018677,0.9984643459320068,0.9984139800071716,0.9987412691116333,0.9986153841018677,0.9986657500267029,0.9989929795265198,0.9987412691116333,0.9989426732063293,0.9985398650169373,0.9987664222717285,0.9987664222717285,0.9988419413566589,0.9987915754318237,0.9985902309417725,0.9987412691116333,0.9983384609222412,0.9987412691116333,0.9989678263664246,0.9988167881965637,0.9987915754318237,0.9987160563468933,0.9988167881965637,0.9988923072814941,0.9989426732063293,0.9987664222717285,0.9990181922912598,0.9990181922912598,0.9988923072814941,0.9988923072814941,0.9990181922912598,0.9990181922912598,0.9989174604415894,0.9988671541213989,0.9984139800071716,0.9989678263664246,0.9988167881965637,0.999043345451355,0.9989174604415894,0.9989678263664246,0.9989426732063293,0.999043345451355,0.9988923072814941,0.9989174604415894,0.9989678263664246,0.9991188645362854,0.9991943836212158,0.9990937113761902,0.999043345451355,0.9989426732063293,0.9991440773010254,0.9989174604415894,0.9991188645362854,0.9991188645362854,0.999043345451355,0.998288094997406,0.9984391331672668,0.9989929795265198,0.9990181922912598,0.9990181922912598,0.9989678263664246,0.9990181922912598,0.9990181922912598,0.9989426732063293,0.9991692304611206,0.999043345451355,0.9991440773010254,0.9990937113761902,0.9990937113761902,0.9991692304611206,0.9991943836212158,0.999043345451355,0.9990937113761902,0.999244749546051,0.9991692304611206,0.9992195963859558,0.9990684986114502,0.9991440773010254,0.9991943836212158,0.9990684986114502,0.999244749546051,0.999244749546051,0.9992195963859558,0.9992195963859558,0.9991692304611206,0.9991692304611206,0.999244749546051,0.9991943836212158,0.9990937113761902,0.999244749546051,0.9992195963859558,0.999244749546051,0.9992951154708862,0.999244749546051,0.9991943836212158,0.999244749546051,0.9992195963859558,0.999244749546051,0.9993202686309814,0.9992951154708862,0.9991943836212158,0.999244749546051,0.9991943836212158,0.9992951154708862,0.9992195963859558,0.9992699027061462,0.9992195963859558,0.9991440773010254,0.9991943836212158,0.9992699027061462,0.9991943836212158,0.9992699027061462,0.9991943836212158,0.9992195963859558,0.999244749546051,0.9992699027061462,0.9992195963859558,0.9993202686309814,0.999244749546051,0.9992195963859558,0.9992951154708862,0.9991943836212158,0.9989929795265198,0.9991692304611206,0.9992195963859558,0.999244749546051,0.999244749546051,0.9992195963859558,0.9992195963859558,0.9992951154708862,0.9992951154708862,0.9993202686309814,0.9992951154708862,0.9992699027061462,0.9992699027061462,0.9993202686309814,0.999244749546051,0.9992699027061462,0.9992195963859558,0.9992699027061462,0.9993454217910767,0.9993202686309814,0.9992699027061462,0.9993454217910767,0.9992195963859558,0.999244749546051,0.9993454217910767,0.9992951154708862,0.9992951154708862,0.9993706345558167,0.9993202686309814,0.9991943836212158,0.9993202686309814,0.9992699027061462,0.999244749546051,0.9993202686309814,0.9992699027061462,0.9992951154708862,0.9993454217910767,0.9993454217910767,0.9992699027061462,0.9992951154708862,0.9992699027061462,0.9991943836212158,0.9993202686309814,0.9992951154708862,0.999244749546051,0.9993706345558167,0.9992699027061462,0.9993454217910767,0.9993202686309814,0.9993454217910767,0.9993202686309814,0.999244749546051,0.9992951154708862,0.9993454217910767,0.9993454217910767,0.9993706345558167,0.9992699027061462,0.9992951154708862,0.9993454217910767,0.9993202686309814,0.9992951154708862,0.9991692304611206,0.9993202686309814,0.9992951154708862,0.9993202686309814,0.9992951154708862,0.9992951154708862,0.9992699027061462,0.999244749546051,0.999244749546051,0.9993202686309814,0.9992699027061462,0.999244749546051,0.999244749546051,0.9993202686309814,0.9993454217910767,0.9993202686309814,0.9993454217910767,0.9993454217910767,0.9993202686309814,0.9993454217910767,0.9992951154708862,0.9993202686309814,0.9993454217910767,0.9993454217910767,0.9992951154708862,0.9992699027061462,0.9992699027061462,0.9993202686309814,0.9993202686309814,0.9991692304611206,0.9992699027061462,0.9993202686309814,0.9993202686309814,0.9993202686309814,0.9993202686309814,0.9992951154708862,0.9993202686309814,0.9991943836212158,0.9992699027061462,0.9992951154708862,0.9993202686309814,0.9992951154708862,0.9992951154708862,0.9993202686309814,0.999244749546051,0.9992951154708862,0.999244749546051,0.9992699027061462,0.9992951154708862,0.9993202686309814,0.9993202686309814,0.9992951154708862,0.9992699027061462,0.9992195963859558,0.9993202686309814,0.9993202686309814,0.9992951154708862,0.9992699027061462,0.9992951154708862,0.9992951154708862,0.9991943836212158,0.9992699027061462,0.9992195963859558,0.9991943836212158,0.9992195963859558,0.999244749546051,0.9991943836212158,0.9991943836212158,0.9992195963859558,0.999244749546051,0.9992951154708862,0.9992951154708862,0.9991943836212158,0.9992951154708862,0.9992699027061462,0.9991943836212158,0.9987915754318237,0.9987915754318237,0.9988419413566589,0.9991188645362854,0.9991188645362854,0.9990937113761902,0.9990684986114502,0.9991188645362854,0.9990937113761902,0.9991692304611206,0.9991692304611206,0.9991440773010254,0.9991440773010254,0.9991440773010254,0.9991943836212158,0.9991943836212158,0.9991943836212158,0.9992195963859558,0.9992195963859558,0.9992699027061462,0.999244749546051,0.999244749546051,0.9992699027061462,0.9992699027061462,0.999244749546051,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.999244749546051,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992951154708862,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.999244749546051,0.9992699027061462,0.9992699027061462,0.9992951154708862,0.9992951154708862,0.9992951154708862,0.999244749546051,0.9992699027061462,0.9992951154708862,0.9992951154708862,0.9992951154708862,0.9992699027061462,0.9992699027061462,0.9992699027061462,0.9992951154708862,0.9992699027061462,0.9992951154708862,0.9992699027061462,0.9992951154708862,0.9992951154708862,0.9992951154708862,0.9992951154708862,0.9992951154708862,0.9992951154708862,0.9992951154708862,0.9992951154708862,0.9993454217910767,0.9992951154708862,0.999244749546051,0.9992951154708862,0.9992951154708862,0.9992699027061462,0.9992699027061462,0.9992951154708862,0.9993454217910767],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Training Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],\"y\":[0.3660100996494293,0.24349793791770935,0.1945408284664154,0.16442807018756866,0.1459839791059494,0.1325918287038803,0.12248614430427551,0.11541732400655746,0.10978361964225769,0.10377529263496399,0.09876283258199692,0.09437920898199081,0.09098777920007706,0.08646167814731598,0.08258946985006332,0.07970559597015381,0.07604299485683441,0.07326896488666534,0.0702146664261818,0.06699485331773758,0.06497791409492493,0.06235495209693909,0.059300217777490616,0.05741691589355469,0.0549149326980114,0.05232033506035805,0.050180207937955856,0.0483008474111557,0.04580184444785118,0.043975114822387695,0.042490869760513306,0.04047587886452675,0.038962651044130325,0.037324607372283936,0.03641616180539131,0.034296028316020966,0.03315284103155136,0.031606342643499374,0.030926838517189026,0.029573408886790276,0.02839331142604351,0.027188438922166824,0.02606910467147827,0.025393066927790642,0.024525806307792664,0.023891892284154892,0.022673437371850014,0.02183234691619873,0.02106395922601223,0.0203644298017025,0.019887380301952362,0.018982049077749252,0.018706122413277626,0.01791226491332054,0.017292022705078125,0.01685858517885208,0.01624089479446411,0.015703454613685608,0.015234449878334999,0.014807923696935177,0.014271353371441364,0.013901091180741787,0.013488723896443844,0.0132112056016922,0.012714577838778496,0.01238690409809351,0.01204613409936428,0.011764089576900005,0.011602209880948067,0.011380130425095558,0.010737564414739609,0.010608656331896782,0.010232039727270603,0.010000793263316154,0.009773917496204376,0.009503224864602089,0.00933031551539898,0.009036924690008163,0.00889027863740921,0.008642981760203838,0.008446989580988884,0.00834704376757145,0.008123456500470638,0.00792169850319624,0.007739434018731117,0.007415566127747297,0.00741151999682188,0.007195225451141596,0.007135464809834957,0.006897151470184326,0.006770957261323929,0.006575775798410177,0.006411690264940262,0.006431766785681248,0.006393773946911097,0.006150000728666782,0.006055391393601894,0.005797036923468113,0.005804832559078932,0.005614533554762602,0.005537979304790497,0.0054466137662529945,0.005256538279354572,0.005127131473273039,0.004962220322340727,0.005029538180679083,0.004946489818394184,0.004880571737885475,0.004746603313833475,0.0046498761512339115,0.005162195768207312,0.005187193397432566,0.004861360415816307,0.0045028808526694775,0.004394865129143,0.004258963279426098,0.004351517651230097,0.004535727668553591,0.004017608240246773,0.003825410734862089,0.0038978580851107836,0.003788321977481246,0.0037276858929544687,0.00370568479411304,0.003564357291907072,0.003509861882776022,0.0035337847657501698,0.0033715851604938507,0.003331707324832678,0.00342632201500237,0.0032079138327389956,0.00321345217525959,0.0031985058449208736,0.003575321286916733,0.003022332675755024,0.0029578441753983498,0.0029443111270666122,0.0028306138701736927,0.0028138563502579927,0.0027678292244672775,0.0029552001506090164,0.002863527275621891,0.002667168155312538,0.0028926024679094553,0.003272162051871419,0.0027605141513049603,0.0025887840893119574,0.0025269631296396255,0.002421148121356964,0.0024170642718672752,0.0024560540914535522,0.002378465374931693,0.0023459182120859623,0.0023209848441183567,0.0024994637351483107,0.002415430499240756,0.0021643396466970444,0.0025516534224152565,0.002621665131300688,0.0022672959603369236,0.00221942737698555,0.0021623799111694098,0.002048538299277425,0.0020590724889189005,0.0019238416571170092,0.0022984452079981565,0.002972651505842805,0.002147675259038806,0.001973850652575493,0.0019086386309936643,0.001843367819674313,0.0019184969132766128,0.0020973265636712313,0.0031337770633399487,0.0019973190501332283,0.001807221444323659,0.001649476820603013,0.0016896642046049237,0.0016764234751462936,0.0016540100332349539,0.0016113664023578167,0.0016025867080315948,0.0016280572162941098,0.0015416371170431376,0.001565469428896904,0.0017668330110609531,0.0015003752196207643,0.0017539896070957184,0.001614091102965176,0.0015899782301858068,0.0016014340799301863,0.002337750280275941,0.0018249046988785267,0.003825092688202858,0.001952661550603807,0.0014779098564758897,0.0013811812968924642,0.0014175963588058949,0.0013426931109279394,0.0012824065051972866,0.0013124747201800346,0.0012117479927837849,0.0011992030777037144,0.0013545406982302666,0.0012320558307692409,0.0013834376586601138,0.0011673873523250222,0.0014397429767996073,0.0018770181341096759,0.004599983338266611,0.004458308219909668,0.015838919207453728,0.008262271992862225,0.007322350051254034,0.006479095201939344,0.005589808337390423,0.004582695662975311,0.0034684529528021812,0.0025249882601201534,0.0020669330842792988,0.001965124625712633,0.0015811520861461759,0.0014275131979957223,0.001301392214372754,0.0012839713599532843,0.0015004245797172189,0.001199915655888617,0.0012373682111501694,0.0013553701573982835,0.0010914250742644072,0.0010581917595118284,0.0010659795952960849,0.0010791418608278036,0.001161938882432878,0.0009864233434200287,0.0010370727395638824,0.0011686075013130903,0.0009726143325679004,0.0009398511028848588,0.0009387127356603742,0.0009329936001449823,0.0009101228206418455,0.0009142193594016135,0.0008773703593760729,0.0009024501778185368,0.0008746570674702525,0.0008538623806089163,0.0008574494277127087,0.0008385975379496813,0.0008334288722835481,0.0008564132731407881,0.0008200216689147055,0.000852942350320518,0.0008112137438729405,0.0008242764743044972,0.0008557786932215095,0.0007921530632302165,0.0007525678956881166,0.0008113189833238721,0.0007772364187985659,0.000773101404774934,0.0007538138306699693,0.0007582436664961278,0.0008057879749685526,0.0007567345164716244,0.0007349408697336912,0.0007214492652565241,0.000706326391082257,0.0007078701164573431,0.0006965715438127518,0.0007279481505975127,0.000741753145121038,0.0006685549742542207,0.0006780700059607625,0.0007235368830151856,0.0006714767660014331,0.0006683130050078034,0.0010513393208384514,0.0013352561509236693,0.0035239756107330322,0.0020838233176618814,0.0008728134562261403,0.0006892490200698376,0.0007017586613073945,0.0007510626455768943,0.00072452612221241,0.0006220453069545329,0.0006079690647311509,0.0006261618109419942,0.0005834682960994542,0.0005850601592101157,0.0007986635318957269,0.0006354011129587889,0.0005885432474315166,0.000567518116440624,0.0005814503529109061,0.0005734218866564333,0.0005755065358243883,0.0005479541141539812,0.0005452576442621648,0.0005637215217575431,0.0005819510552100837,0.000523229711689055,0.0005741661880165339,0.0005248843226581812,0.0005775138270109892,0.0005487597081810236,0.00062743597663939,0.0006412669899873435,0.0005107597098685801,0.000635001459158957,0.0005255365977063775,0.0005051458138041198,0.0004980341182090342,0.0004796970752067864,0.0005169248324818909,0.0004760021110996604,0.0005014060880057514,0.000474272615974769,0.0005029859021306038,0.0005204621702432632,0.00045731826685369015,0.0005080064292997122,0.0004389530804473907,0.000534180726390332,0.0004483985248953104,0.00048767923726700246,0.0004806122451554984,0.0004353448748588562,0.0004831851983908564,0.0005941467243246734,0.0004384306084830314,0.0005175606347620487,0.00043837892008014023,0.0008091013878583908,0.0008620452135801315,0.0005236757569946349,0.0004194809007458389,0.00042864124407060444,0.0005462421686388552,0.0005978510598652065,0.00042298599146306515,0.0004392925766296685,0.0004606909933499992,0.00045521953143179417,0.00044044331298209727,0.0010610889876261353,0.0032075089402496815,0.0023917534854263067,0.0011597203556448221,0.0007258685072883964,0.0006549656973220408,0.0005597063573077321,0.0004210177285131067,0.00041971291648223996,0.0004200180701445788,0.00038522464456036687,0.00040533143328502774,0.00041890382999554276,0.00041813976713456213,0.0003692001919262111,0.0003689666627906263,0.0004182553384453058,0.00043577986070886254,0.0003693123289849609,0.00043094591819681227,0.00038801797199994326,0.00033699432970024645,0.000565677706617862,0.0009783765999600291,0.0004588966548908502,0.00036826779250986874,0.00037674428313039243,0.0003829410416074097,0.00038179074181243777,0.00034871321986429393,0.0006352358032017946,0.0007844667416065931,0.0005215299315750599,0.00037347900797612965,0.0007411750266328454,0.00043246877612546086,0.00034051938564516604,0.0003635530301835388,0.0004204832366667688,0.0003915374109055847,0.0004339977749623358,0.0004061757354065776,0.00034319001133553684,0.0003082296752836555,0.00032202445436269045,0.00039229137473739684,0.0005451087490655482,0.00038825467345304787,0.0003046210913453251,0.0003251555608585477,0.0005939688417129219,0.0010782666504383087,0.00039609192754141986,0.002249654848128557,0.0019090271089226007,0.0013362898025661707,0.002040768973529339,0.001175074023194611,0.0007490188581869006,0.001292771310545504,0.001254933886229992,0.0006864580791443586,0.0004991869791410863,0.00043450042721815407,0.0003094553539995104,0.0028796661645174026,0.006328631192445755,0.005060636904090643,0.0036111760418862104,0.009153628721833229,0.007627604529261589,0.0057671573013067245,0.004162897821515799,0.0029683061875402927,0.0019796674605458975,0.0013818705920130014,0.0011711621191352606,0.001120480359531939,0.0008753373986110091,0.0006973647396080196,0.0006105332868173718,0.0005623592878691852,0.0005111150676384568,0.0004798786249011755,0.0004423221689648926,0.0004182495176792145,0.00041099448571912944,0.0003893250832334161,0.0003809442277997732,0.0003724553098436445,0.0003628870763350278,0.0003557231102604419,0.00034857154241763055,0.0003373146173544228,0.00032882532104849815,0.00033156934659928083,0.00031726653105579317,0.00033488142071291804,0.0003210129798389971,0.0002992073423229158,0.00030264537781476974,0.0003012044762726873,0.00028737285174429417,0.0002907314628828317,0.0002883650304283947,0.00028215491329319775,0.00026976599474437535,0.00026914954651147127,0.0002814586041495204,0.00027245833189226687,0.0002675495343282819,0.0002672088739927858,0.00027787452563643456,0.00026410730788484216,0.0002543250157032162,0.00025601976085454226,0.00025891067343764007,0.0002512390783522278,0.00027111999224871397,0.0002539890992920846,0.0002784528478514403,0.0003925197815988213,0.0002957670367322862,0.0002894421631935984,0.0002531739301048219,0.00024105969350785017,0.00025687742163427174,0.00025225162971764803,0.00028524722438305616,0.00025897775776684284,0.0002604502660688013,0.0002470320032443851,0.00023548764875158668,0.00027359489467926323,0.00028149422723799944,0.0002477816306054592,0.00023321474145632237,0.00027211374253965914,0.0002465415745973587,0.0002547905023675412,0.0002479664981365204,0.0002490593178663403,0.00023336528101935983,0.00023602377041243017,0.0002498393296264112,0.00027757801581174135,0.0002249542740173638,0.0005201424937695265,0.0006328577292151749,0.0007333746762014925,0.00032236380502581596,0.0004711897927336395,0.00032228342024609447,0.00024348762235604227],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"Validation Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499],\"y\":[0.3458364009857178,0.24306997656822205,0.19320426881313324,0.1519152969121933,0.13598710298538208,0.12331870943307877,0.10272279381752014,0.10500472038984299,0.09173526614904404,0.08567027002573013,0.087431401014328,0.07861417531967163,0.07961064577102661,0.0717722475528717,0.0713743269443512,0.06653833389282227,0.06340736895799637,0.06669348478317261,0.060034412890672684,0.05748040974140167,0.05869177728891373,0.05953730642795563,0.04989595711231232,0.05707601085305214,0.052460622042417526,0.050898097455501556,0.04400407522916794,0.045956216752529144,0.04539675638079643,0.0409247986972332,0.04378413408994675,0.040470633655786514,0.0445655919611454,0.032641299068927765,0.03996355086565018,0.03343762084841728,0.031388092786073685,0.034121476113796234,0.0380917564034462,0.030993308871984482,0.030715711414813995,0.029762037098407745,0.02725180611014366,0.029823120683431625,0.02382398210465908,0.03026474080979824,0.024048199877142906,0.02558055892586708,0.02479245513677597,0.02487955056130886,0.0245966799557209,0.022489305585622787,0.024536794051527977,0.020373301580548286,0.023317532613873482,0.020027123391628265,0.02059185318648815,0.020295463502407074,0.02051897905766964,0.019551588222384453,0.017427965998649597,0.018393006175756454,0.015958214178681374,0.017803914844989777,0.0167177002876997,0.015589697286486626,0.017588509246706963,0.0162180308252573,0.017563210800290108,0.014548316597938538,0.013862300664186478,0.015236539766192436,0.014329417608678341,0.01461648941040039,0.013559291139245033,0.013067458756268024,0.013918028213083744,0.013245690613985062,0.012693673372268677,0.012265529483556747,0.01234766747802496,0.01396726444363594,0.012238920666277409,0.010927680879831314,0.011025246232748032,0.010721713304519653,0.010310274548828602,0.00993909128010273,0.011449072510004044,0.011799578554928303,0.011117629706859589,0.010479599237442017,0.010132916271686554,0.01126194093376398,0.011281346902251244,0.010714863426983356,0.010892949067056179,0.009404294192790985,0.009216547012329102,0.009321079589426517,0.00940057821571827,0.009160087443888187,0.009500867687165737,0.008970090188086033,0.008707499131560326,0.009008074179291725,0.008164938539266586,0.008843832649290562,0.009260430932044983,0.008758054114878178,0.010673841461539268,0.010194783098995686,0.009208118543028831,0.008159481920301914,0.008619084022939205,0.008675402961671352,0.009360911324620247,0.008273853920400143,0.007814371958374977,0.007554397452622652,0.00840388610959053,0.00807978492230177,0.008172037079930305,0.007947472855448723,0.008141448721289635,0.008047299459576607,0.008296974934637547,0.006863105576485395,0.0074834078550338745,0.006836916320025921,0.007546289823949337,0.007828150875866413,0.007951419800519943,0.007524886168539524,0.006622565910220146,0.007371347863227129,0.007161115296185017,0.006735115312039852,0.006725222337990999,0.006915637291967869,0.007069218438118696,0.007673226296901703,0.007669616024941206,0.009123493917286396,0.0072821956127882,0.007219686172902584,0.006582568399608135,0.0065840971656143665,0.006635007914155722,0.0066881319507956505,0.006547333672642708,0.0065046632662415504,0.00653070118278265,0.007005931343883276,0.007073415443301201,0.006720290053635836,0.00647954735904932,0.007385620381683111,0.007583784870803356,0.0065479702316224575,0.006643311586230993,0.006440649274736643,0.005521862767636776,0.006366097833961248,0.005793893244117498,0.008555592969059944,0.006183091085404158,0.006260410416871309,0.00581933930516243,0.005990518257021904,0.006796538829803467,0.0065739452838897705,0.009077558293938637,0.006817907560616732,0.005815635900944471,0.006178577430546284,0.005999370478093624,0.006409629713743925,0.00603506388142705,0.006176813505589962,0.005926739424467087,0.006306320428848267,0.005594140850007534,0.00564303994178772,0.006234537344425917,0.006032930221408606,0.005745492875576019,0.006126348860561848,0.006250016391277313,0.006543153431266546,0.0076463413424789906,0.006158141884952784,0.008966930210590363,0.0074293846264481544,0.006280736997723579,0.006082082167267799,0.005926403682678938,0.005913461092859507,0.006241714581847191,0.006133821792900562,0.006012848578393459,0.0057595157995820045,0.005665394477546215,0.0058912429958581924,0.006053462624549866,0.006361338775604963,0.005774423014372587,0.007317207287997007,0.005970424972474575,0.010949146002531052,0.00861914362758398,0.016969764605164528,0.01617351733148098,0.013852384872734547,0.012752457521855831,0.011476865038275719,0.01023627258837223,0.008551769889891148,0.007681680377572775,0.007597246672958136,0.006890018004924059,0.006740519776940346,0.006454456131905317,0.0063559142872691154,0.006304076407104731,0.006295600440353155,0.0061446488834917545,0.006673948373645544,0.006279713939875364,0.005941551644355059,0.006092679221183062,0.0059691863134503365,0.006480839569121599,0.006169704720377922,0.005946263670921326,0.006486901547759771,0.006012268830090761,0.005893183406442404,0.005925225093960762,0.006043206434696913,0.0061364443972706795,0.006088295951485634,0.006009345408529043,0.0061066048219799995,0.006270894780755043,0.006064911372959614,0.006024159491062164,0.006041832268238068,0.0060289166867733,0.006016177125275135,0.00619171280413866,0.0061496952548623085,0.006290139630436897,0.00617483863607049,0.006066511385142803,0.006170229054987431,0.006279176566749811,0.006173775065690279,0.006246676668524742,0.006226987577974796,0.006266686134040356,0.006180165335536003,0.0063591101206839085,0.006581807509064674,0.006440329365432262,0.006240637972950935,0.0063822343945503235,0.006386743392795324,0.006455875933170319,0.0063888393342494965,0.006562471855431795,0.006515295710414648,0.006517511792480946,0.006296329665929079,0.006522449664771557,0.006519787013530731,0.006551997736096382,0.00738179124891758,0.009537451900541782,0.009539364837110043,0.007187027018517256,0.006906081922352314,0.006743801757693291,0.006738141644746065,0.006868788506835699,0.006849871948361397,0.006761658005416393,0.006786034908145666,0.006844723597168922,0.006809201557189226,0.006909433286637068,0.00680664973333478,0.006798640824854374,0.007000101264566183,0.00688474765047431,0.006933684926480055,0.006853190716356039,0.0069060176610946655,0.006940869148820639,0.006950163748115301,0.006882763467729092,0.007058301940560341,0.006997050251811743,0.006886663846671581,0.007179412059485912,0.006935361307114363,0.007016638293862343,0.007302197627723217,0.007096430752426386,0.007296509109437466,0.007132401689887047,0.007187759503722191,0.0073089743964374065,0.0072730123065412045,0.007256783079355955,0.007405425887554884,0.007159425877034664,0.0072286492213606834,0.007377319969236851,0.007417044602334499,0.007527040783315897,0.0072998590767383575,0.0075083705596625805,0.007464588154107332,0.0073435381054878235,0.00761503865942359,0.007500677835196257,0.007654834538698196,0.0076590715907514095,0.007559900637716055,0.007929803803563118,0.00767100602388382,0.0076319375075399876,0.007675516419112682,0.007812924683094025,0.007629730273038149,0.007854286581277847,0.007851243019104004,0.007889379747211933,0.008212190121412277,0.008064469322562218,0.007957876659929752,0.007931254804134369,0.0081210657954216,0.00792615581303835,0.008070758543908596,0.008590321987867355,0.011956936679780483,0.00878259539604187,0.008540679700672626,0.00826820358633995,0.008399806916713715,0.008348850533366203,0.008284851908683777,0.008196205832064152,0.00818689726293087,0.008444624952971935,0.008394812233746052,0.008352462202310562,0.008423683233559132,0.00847100280225277,0.008217321708798409,0.008362086489796638,0.008556826040148735,0.008577486500144005,0.00841353926807642,0.008654550649225712,0.00862053595483303,0.009424395859241486,0.008978459052741528,0.008669550530612469,0.008602166548371315,0.008758663199841976,0.00881907157599926,0.008787752129137516,0.00858401320874691,0.009540440514683723,0.009288056753575802,0.00867144949734211,0.008829360827803612,0.009235229343175888,0.008949056267738342,0.008935771882534027,0.008788667619228363,0.00914038997143507,0.009064087644219398,0.009167945012450218,0.009025494568049908,0.00913040991872549,0.009129412472248077,0.008889039978384972,0.00922021921724081,0.008959615603089333,0.009144390001893044,0.009120780974626541,0.009351427666842937,0.01089389342814684,0.009677440859377384,0.009511496871709824,0.012472281232476234,0.011675202287733555,0.011371058411896229,0.011612351052463055,0.01110696792602539,0.010610727593302727,0.011517477221786976,0.010943496599793434,0.01044967956840992,0.010046389885246754,0.00969021674245596,0.009943089447915554,0.017107892781496048,0.016520705074071884,0.014734684489667416,0.013257047161459923,0.01890648528933525,0.018243316560983658,0.01678258366882801,0.01366492360830307,0.012412874028086662,0.01176152378320694,0.011435492895543575,0.011094469577074051,0.010688531212508678,0.010644416324794292,0.010575341992080212,0.010540815070271492,0.010444694198668003,0.010353203862905502,0.010310634039342403,0.010282590053975582,0.010239681228995323,0.010133408010005951,0.010118839330971241,0.010098876431584358,0.010092691518366337,0.010102935135364532,0.010065027512609959,0.010068933479487896,0.010133764706552029,0.010062874294817448,0.010086452588438988,0.010096768848598003,0.009962758980691433,0.010047086514532566,0.01014220342040062,0.01004916150122881,0.010040038265287876,0.010068802163004875,0.010066572576761246,0.010132551193237305,0.010087456554174423,0.010072164237499237,0.01007554680109024,0.010069800540804863,0.010064437054097652,0.010130769573152065,0.009968575090169907,0.010103478096425533,0.010116365738213062,0.010028096847236156,0.010110540315508842,0.010069337673485279,0.010114981792867184,0.010082454420626163,0.01012468058615923,0.009825834073126316,0.01009866688400507,0.009973286651074886,0.009995260275900364,0.009999409317970276,0.010179601609706879,0.01011065486818552,0.009921728633344173,0.010114656761288643,0.01001767162233591,0.010193862952291965,0.01013914868235588,0.010175253264605999,0.009904971346259117,0.010156625881791115,0.010030381381511688,0.01021344680339098,0.010036956518888474,0.010137762874364853,0.01012226939201355,0.010143747553229332,0.01006107684224844,0.01001387182623148,0.010220181196928024,0.010080191306769848,0.010190685279667377,0.010255401954054832,0.010567760095000267,0.010307044722139835,0.010080714710056782,0.010320342145860195,0.010376976802945137,0.010153750889003277,0.010355062782764435],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0]},\"title\":{\"text\":\"Training and Validation Plot\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0b29071d-cf20-4d20-beb2-e941372b2f0f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "93Lp7Ou_r1V5"
      },
      "id": "93Lp7Ou_r1V5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}